{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Implementation of a working memory model.\n",
    "Literature:\n",
    "Compte, A., Brunel, N., Goldman-Rakic, P. S., & Wang, X. J. (2000). Synaptic mechanisms and\n",
    "network dynamics underlying spatial working memory in a cortical network model.\n",
    "Cerebral Cortex, 10(9), 910-923.\n",
    "\n",
    "Some parts of this implementation are inspired by material from\n",
    "*Stanford University, BIOE 332: Large-Scale Neural Modeling, Kwabena Boahen & Tatiana Engel, 2013*,\n",
    "online available.\n",
    "\n",
    "Note: Most parameters differ from the original publication.\n",
    "\"\"\"\n",
    "\n",
    "# This file is part of the exercise code repository accompanying\n",
    "# the book: Neuronal Dynamics (see http://neuronaldynamics.epfl.ch)\n",
    "# located at http://github.com/EPFL-LCN/neuronaldynamics-exercises.\n",
    "\n",
    "# This free software: you can redistribute it and/or modify it under\n",
    "# the terms of the GNU General Public License 2.0 as published by the\n",
    "# Free Software Foundation. You should have received a copy of the\n",
    "# GNU General Public License along with the repository. If not,\n",
    "# see http://www.gnu.org/licenses/.\n",
    "\n",
    "# Should you reuse and publish the code for your own purposes,\n",
    "# please cite the book or point to the webpage http://neuronaldynamics.epfl.ch.\n",
    "\n",
    "# Wulfram Gerstner, Werner M. Kistler, Richard Naud, and Liam Paninski.\n",
    "# Neuronal Dynamics: From Single Neurons to Networks and Models of Cognition.\n",
    "# Cambridge University Press, 2014.\n",
    "\n",
    "import brian2 as b2\n",
    "from brian2 import NeuronGroup, Synapses, PoissonInput, network_operation\n",
    "from brian2.monitors import StateMonitor, SpikeMonitor, PopulationRateMonitor\n",
    "from random import sample\n",
    "from collections import deque\n",
    "from neurodynex.tools import plot_tools\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from scipy.special import erf\n",
    "from numpy.fft import rfft, irfft\n",
    "\n",
    "b2.defaultclock.dt = 0.05 * b2.ms\n",
    "\n",
    "\n",
    "[docs]def simulate_wm(\n",
    "        N_excitatory=1024, N_inhibitory=256,\n",
    "        N_extern_poisson=1000, poisson_firing_rate=1.4 * b2.Hz, weight_scaling_factor=2.,\n",
    "        sigma_weight_profile=20., Jpos_excit2excit=1.6,\n",
    "        stimulus_center_deg=180, stimulus_width_deg=40, stimulus_strength=0.07 * b2.namp,\n",
    "        t_stimulus_start=0 * b2.ms, t_stimulus_duration=0 * b2.ms,\n",
    "        distractor_center_deg=90, distractor_width_deg=40, distractor_strength=0.0 * b2.namp,\n",
    "        t_distractor_start=0 * b2.ms, t_distractor_duration=0 * b2.ms,\n",
    "        G_inhib2inhib=.35 * 1.024 * b2.nS,\n",
    "        G_inhib2excit=.35 * 1.336 * b2.nS,\n",
    "        G_excit2excit=.35 * 0.381 * b2.nS,\n",
    "        G_excit2inhib=.35 * 1.2 * 0.292 * b2.nS,\n",
    "        monitored_subset_size=1024, sim_time=800. * b2.ms):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        N_excitatory (int): Size of the excitatory population\n",
    "        N_inhibitory (int): Size of the inhibitory population\n",
    "        weight_scaling_factor (float): weight prefactor. When increasing the size of the populations,\n",
    "            the synaptic weights have to be decreased. Using the default values, we have\n",
    "            N_excitatory*weight_scaling_factor = 2048 and N_inhibitory*weight_scaling_factor=512\n",
    "        N_extern_poisson (int): Size of the external input population (Poisson input)\n",
    "        poisson_firing_rate (Quantity): Firing rate of the external population\n",
    "        sigma_weight_profile (float): standard deviation of the gaussian input profile in\n",
    "            the excitatory population.\n",
    "        Jpos_excit2excit (float): Strength of the recurrent input within the excitatory population.\n",
    "            Jneg_excit2excit is computed from sigma_weight_profile, Jpos_excit2excit and the normalization\n",
    "            condition.\n",
    "        stimulus_center_deg (float): Center of the stimulus in [0, 360]\n",
    "        stimulus_width_deg (float): width of the stimulus. All neurons in\n",
    "            stimulus_center_deg +\\- (stimulus_width_deg/2) receive the same input current\n",
    "        stimulus_strength (Quantity): Input current to the neurons at stimulus_center_deg +\\- (stimulus_width_deg/2)\n",
    "        t_stimulus_start (Quantity): time when the input stimulus is turned on\n",
    "        t_stimulus_duration (Quantity): duration of the stimulus.\n",
    "        distractor_center_deg (float): Center of the distractor in [0, 360]\n",
    "        distractor_width_deg (float): width of the distractor. All neurons in\n",
    "            distractor_center_deg +\\- (distractor_width_deg/2) receive the same input current\n",
    "            distractor_strength (Quantity): Input current to the neurons at\n",
    "            distractor_center_deg +\\- (distractor_width_deg/2)\n",
    "        t_distractor_start (Quantity): time when the distractor is turned on\n",
    "        t_distractor_duration (Quantity): duration of the distractor.\n",
    "        G_inhib2inhib (Quantity): projections from inhibitory to inhibitory population (later\n",
    "            rescaled by weight_scaling_factor)\n",
    "        G_inhib2excit (Quantity): projections from inhibitory to excitatory population (later\n",
    "            rescaled by weight_scaling_factor)\n",
    "        G_excit2excit (Quantity): projections from excitatory to excitatory population (later\n",
    "            rescaled by weight_scaling_factor)\n",
    "        G_excit2inhib (Quantity): projections from excitatory to inhibitory population (later\n",
    "            rescaled by weight_scaling_factor)\n",
    "        monitored_subset_size (int): nr of neurons for which a Spike- and Voltage monitor\n",
    "            is registered.\n",
    "        sim_time (Quantity): simulation time\n",
    "\n",
    "    Returns:\n",
    "\n",
    "       results (tuple):\n",
    "       rate_monitor_excit (Brian2 PopulationRateMonitor for the excitatory population),\n",
    "        spike_monitor_excit, voltage_monitor_excit, idx_monitored_neurons_excit,\\\n",
    "        rate_monitor_inhib, spike_monitor_inhib, voltage_monitor_inhib, idx_monitored_neurons_inhib,\\\n",
    "        weight_profile_45 (The weights profile for the neuron with preferred direction = 45deg).\n",
    "    \"\"\"\n",
    "    # specify the excitatory pyramidal cells:\n",
    "    Cm_excit = 0.5 * b2.nF  # membrane capacitance of excitatory neurons\n",
    "    G_leak_excit = 25.0 * b2.nS  # leak conductance\n",
    "    E_leak_excit = -70.0 * b2.mV  # reversal potential\n",
    "    v_firing_threshold_excit = -50.0 * b2.mV  # spike condition\n",
    "    v_reset_excit = -60.0 * b2.mV  # reset voltage after spike\n",
    "    t_abs_refract_excit = 2.0 * b2.ms  # absolute refractory period\n",
    "\n",
    "    # specify the weight profile in the recurrent population\n",
    "    # std-dev of the gaussian weight profile around the prefered direction\n",
    "    # sigma_weight_profile = 12.0  # std-dev of the gaussian weight profile around the prefered direction\n",
    "\n",
    "    #\n",
    "    # Jneg_excit2excit = 0\n",
    "\n",
    "    # specify the inhibitory interneurons:\n",
    "    Cm_inhib = 0.2 * b2.nF\n",
    "    G_leak_inhib = 20.0 * b2.nS\n",
    "    E_leak_inhib = -70.0 * b2.mV\n",
    "    v_firing_threshold_inhib = -50.0 * b2.mV\n",
    "    v_reset_inhib = -60.0 * b2.mV\n",
    "    t_abs_refract_inhib = 1.0 * b2.ms\n",
    "\n",
    "    # specify the AMPA synapses\n",
    "    E_AMPA = 0.0 * b2.mV\n",
    "    tau_AMPA = .9 * 2.0 * b2.ms\n",
    "\n",
    "    # specify the GABA synapses\n",
    "    E_GABA = -70.0 * b2.mV\n",
    "    tau_GABA = 10.0 * b2.ms\n",
    "\n",
    "    # specify the NMDA synapses\n",
    "    E_NMDA = 0.0 * b2.mV\n",
    "    tau_NMDA_s = .65 * 100.0 * b2.ms  # orig: 100\n",
    "    tau_NMDA_x = .94 * 2.0 * b2.ms\n",
    "    alpha_NMDA = 0.5 * b2.kHz\n",
    "\n",
    "    # projections from the external population\n",
    "    G_extern2inhib = 2.38 * b2.nS\n",
    "    G_extern2excit = 3.1 * b2.nS\n",
    "\n",
    "    # projectsions from the inhibitory populations\n",
    "    G_inhib2inhib *= weight_scaling_factor\n",
    "    G_inhib2excit *= weight_scaling_factor\n",
    "\n",
    "    # projections from the excitatory population\n",
    "    G_excit2excit *= weight_scaling_factor\n",
    "    G_excit2inhib *= weight_scaling_factor  # todo: verify this scaling\n",
    "\n",
    "    t_stimulus_end = t_stimulus_start + t_stimulus_duration\n",
    "    t_distractor_end = t_distractor_start + t_distractor_duration\n",
    "    # compute the simulus index\n",
    "    stim_center_idx = int(round(N_excitatory / 360. * stimulus_center_deg))\n",
    "    stim_width_idx = int(round(N_excitatory / 360. * stimulus_width_deg / 2))\n",
    "    stim_target_idx = [idx % N_excitatory\n",
    "                       for idx in range(stim_center_idx - stim_width_idx, stim_center_idx + stim_width_idx + 1)]\n",
    "    # compute the distractor index\n",
    "    distr_center_idx = int(round(N_excitatory / 360. * distractor_center_deg))\n",
    "    distr_width_idx = int(round(N_excitatory / 360. * distractor_width_deg / 2))\n",
    "    distr_target_idx = [idx % N_excitatory for idx in range(distr_center_idx - distr_width_idx,\n",
    "                                                            distr_center_idx + distr_width_idx + 1)]\n",
    "\n",
    "    # precompute the weight profile for the recurrent population\n",
    "    tmp = math.sqrt(2. * math.pi) * sigma_weight_profile * erf(180. / math.sqrt(2.) / sigma_weight_profile) / 360.\n",
    "    Jneg_excit2excit = (1. - Jpos_excit2excit * tmp) / (1. - tmp)\n",
    "    presyn_weight_kernel = \\\n",
    "        [(Jneg_excit2excit +\n",
    "          (Jpos_excit2excit - Jneg_excit2excit) *\n",
    "          math.exp(-.5 * (360. * min(j, N_excitatory - j) / N_excitatory) ** 2 / sigma_weight_profile ** 2))\n",
    "         for j in range(N_excitatory)]\n",
    "    # validate the normalization condition: (360./N_excitatory)*sum(presyn_weight_kernel)/360.\n",
    "    fft_presyn_weight_kernel = rfft(presyn_weight_kernel)\n",
    "    weight_profile_45 = deque(presyn_weight_kernel)\n",
    "    rot_dist = int(round(len(weight_profile_45) / 8))\n",
    "    weight_profile_45.rotate(rot_dist)\n",
    "\n",
    "    # define the inhibitory population\n",
    "    inhib_lif_dynamics = \"\"\"\n",
    "        s_NMDA_total : 1  # the post synaptic sum of s. compare with s_NMDA_presyn\n",
    "        dv/dt = (\n",
    "        - G_leak_inhib * (v-E_leak_inhib)\n",
    "        - G_extern2inhib * s_AMPA * (v-E_AMPA)\n",
    "        - G_inhib2inhib * s_GABA * (v-E_GABA)\n",
    "        - G_excit2inhib * s_NMDA_total * (v-E_NMDA)/(1.0+1.0*exp(-0.062*v/volt)/3.57)\n",
    "        )/Cm_inhib : volt (unless refractory)\n",
    "        ds_AMPA/dt = -s_AMPA/tau_AMPA : 1\n",
    "        ds_GABA/dt = -s_GABA/tau_GABA : 1\n",
    "    \"\"\"\n",
    "\n",
    "    inhib_pop = NeuronGroup(\n",
    "        N_inhibitory, model=inhib_lif_dynamics,\n",
    "        threshold=\"v>v_firing_threshold_inhib\", reset=\"v=v_reset_inhib\", refractory=t_abs_refract_inhib,\n",
    "        method=\"rk2\")\n",
    "    # initialize with random voltages:\n",
    "    inhib_pop.v = numpy.random.uniform(v_reset_inhib / b2.mV, high=v_firing_threshold_inhib / b2.mV,\n",
    "                                       size=N_inhibitory) * b2.mV\n",
    "    # set the connections: inhib2inhib\n",
    "    syn_inhib2inhib = Synapses(inhib_pop, target=inhib_pop, on_pre=\"s_GABA += 1.0\", delay=0.0 * b2.ms)\n",
    "    syn_inhib2inhib.connect(condition=\"i!=j\", p=1.0)\n",
    "    # set the connections: extern2inhib\n",
    "    input_ext2inhib = PoissonInput(target=inhib_pop, target_var=\"s_AMPA\",\n",
    "                                   N=N_extern_poisson, rate=poisson_firing_rate, weight=1.0)\n",
    "\n",
    "    # specify the excitatory population:\n",
    "    excit_lif_dynamics = \"\"\"\n",
    "        I_stim : amp\n",
    "        s_NMDA_total : 1  # the post synaptic sum of s. compare with s_NMDA_presyn\n",
    "        dv/dt = (\n",
    "        - G_leak_excit * (v-E_leak_excit)\n",
    "        - G_extern2excit * s_AMPA * (v-E_AMPA)\n",
    "        - G_inhib2excit * s_GABA * (v-E_GABA)\n",
    "        - G_excit2excit * s_NMDA_total * (v-E_NMDA)/(1.0+1.0*exp(-0.062*v/volt)/3.57)\n",
    "        + I_stim\n",
    "        )/Cm_excit : volt (unless refractory)\n",
    "        ds_AMPA/dt = -s_AMPA/tau_AMPA : 1\n",
    "        ds_GABA/dt = -s_GABA/tau_GABA : 1\n",
    "        ds_NMDA/dt = -s_NMDA/tau_NMDA_s + alpha_NMDA * x * (1-s_NMDA) : 1\n",
    "        dx/dt = -x/tau_NMDA_x : 1\n",
    "    \"\"\"\n",
    "\n",
    "    excit_pop = NeuronGroup(N_excitatory, model=excit_lif_dynamics,\n",
    "                            threshold=\"v>v_firing_threshold_excit\", reset=\"v=v_reset_excit; x+=1.0\",\n",
    "                            refractory=t_abs_refract_excit, method=\"rk2\")\n",
    "    # initialize with random voltages:\n",
    "    excit_pop.v = numpy.random.uniform(v_reset_excit / b2.mV, high=v_firing_threshold_excit / b2.mV,\n",
    "                                       size=N_excitatory) * b2.mV\n",
    "    excit_pop.I_stim = 0. * b2.namp\n",
    "    # set the connections: extern2excit\n",
    "    input_ext2excit = PoissonInput(target=excit_pop, target_var=\"s_AMPA\",\n",
    "                                   N=N_extern_poisson, rate=poisson_firing_rate, weight=1.0)\n",
    "\n",
    "    # set the connections: inhibitory to excitatory\n",
    "    syn_inhib2excit = Synapses(inhib_pop, target=excit_pop, on_pre=\"s_GABA += 1.0\")\n",
    "    syn_inhib2excit.connect(p=1.0)\n",
    "\n",
    "    # set the connections: excitatory to inhibitory NMDA connections\n",
    "    syn_excit2inhib = Synapses(excit_pop, inhib_pop,\n",
    "                               model=\"s_NMDA_total_post = s_NMDA_pre : 1 (summed)\", method=\"rk2\")\n",
    "    syn_excit2inhib.connect(p=1.0)\n",
    "\n",
    "    # # set the connections: UNSTRUCTURED excitatory to excitatory\n",
    "    # syn_excit2excit = Synapses(excit_pop, excit_pop,\n",
    "    #        model= \"s_NMDA_total_post = s_NMDA_pre : 1 (summed)\", method=\"rk2\")\n",
    "    # syn_excit2excit.connect(condition=\"i!=j\", p=1.)\n",
    "\n",
    "    # set the STRUCTURED recurrent input. use a network_operation\n",
    "    @network_operation()\n",
    "    def update_nmda_sum():\n",
    "        fft_s_NMDA = rfft(excit_pop.s_NMDA)\n",
    "        fft_s_NMDA_total = numpy.multiply(fft_presyn_weight_kernel, fft_s_NMDA)\n",
    "        s_NMDA_tot = irfft(fft_s_NMDA_total)\n",
    "        excit_pop.s_NMDA_total_ = s_NMDA_tot\n",
    "\n",
    "    @network_operation(dt=1 * b2.ms)\n",
    "    def stimulate_network(t):\n",
    "        if t >= t_stimulus_start and t < t_stimulus_end:\n",
    "            # excit_pop[stim_start_i - 15:stim_start_i + 15].I_stim = 0.25 * b2.namp\n",
    "            # Todo: review indexing\n",
    "            # print(\"stim on\")\n",
    "            excit_pop.I_stim[stim_target_idx] = stimulus_strength\n",
    "        else:\n",
    "            # print(\"stim off\")\n",
    "            excit_pop.I_stim = 0. * b2.namp\n",
    "        # add distractor\n",
    "        if t >= t_distractor_start and t < t_distractor_end:\n",
    "            excit_pop.I_stim[distr_target_idx] = distractor_strength\n",
    "\n",
    "    def get_monitors(pop, nr_monitored, N):\n",
    "        nr_monitored = min(nr_monitored, (N))\n",
    "        idx_monitored_neurons = \\\n",
    "            [int(math.ceil(k))\n",
    "             for k in numpy.linspace(0, N - 1, nr_monitored + 2)][1:-1]  # sample(range(N), nr_monitored)\n",
    "        rate_monitor = PopulationRateMonitor(pop)\n",
    "        # record= some_list is not supported? :-(\n",
    "        spike_monitor = SpikeMonitor(pop, record=idx_monitored_neurons)\n",
    "        voltage_monitor = StateMonitor(pop, \"v\", record=idx_monitored_neurons)\n",
    "        return rate_monitor, spike_monitor, voltage_monitor, idx_monitored_neurons\n",
    "\n",
    "    # collect data of a subset of neurons:\n",
    "    rate_monitor_inhib, spike_monitor_inhib, voltage_monitor_inhib, idx_monitored_neurons_inhib = \\\n",
    "        get_monitors(inhib_pop, monitored_subset_size, N_inhibitory)\n",
    "\n",
    "    rate_monitor_excit, spike_monitor_excit, voltage_monitor_excit, idx_monitored_neurons_excit = \\\n",
    "        get_monitors(excit_pop, monitored_subset_size, N_excitatory)\n",
    "\n",
    "    b2.run(sim_time)\n",
    "    return \\\n",
    "        rate_monitor_excit, spike_monitor_excit, voltage_monitor_excit, idx_monitored_neurons_excit,\\\n",
    "        rate_monitor_inhib, spike_monitor_inhib, voltage_monitor_inhib, idx_monitored_neurons_inhib,\\\n",
    "        weight_profile_45\n",
    "\n",
    "\n",
    "\n",
    "[docs]def getting_started():\n",
    "    b2.defaultclock.dt = 0.1 * b2.ms\n",
    "    rate_monitor_excit, spike_monitor_excit, voltage_monitor_excit, idx_monitored_neurons_excit,\\\n",
    "        rate_monitor_inhib, spike_monitor_inhib, voltage_monitor_inhib, idx_monitored_neurons_inhib,\\\n",
    "        weight_profile\\\n",
    "        = simulate_wm(N_excitatory=256, N_inhibitory=64, weight_scaling_factor=8., sim_time=500. * b2.ms,\n",
    "                      stimulus_center_deg=120, t_stimulus_start=100 * b2.ms, t_stimulus_duration=200 * b2.ms,\n",
    "                      stimulus_strength=.07 * b2.namp)\n",
    "    plot_tools.plot_network_activity(rate_monitor_excit, spike_monitor_excit, voltage_monitor_excit,\n",
    "                                     t_min=0. * b2.ms)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    getting_started()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
